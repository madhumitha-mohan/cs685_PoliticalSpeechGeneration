{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Approach_2.ipynb",
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "id": "EfcRMHrVkQQN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "756496bf-b7d9-4d2c-e272-b94f0ee28a0e"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.14.1)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.46)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.4.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.3)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.8.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.2.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.62.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.6)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.6.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive', force_remount=True)"
      ],
      "metadata": {
        "id": "eNBSgpJun_qC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c3694bf4-013e-4dda-98ba-22c58c289310"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/uber-research/PPLM.git"
      ],
      "metadata": {
        "id": "2GjxK3_vMzOO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0be235b3-6279-4400-a776-b4e825f0340b"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'PPLM'...\n",
            "remote: Enumerating objects: 276, done.\u001b[K\n",
            "remote: Counting objects: 100% (26/26), done.\u001b[K\n",
            "remote: Compressing objects: 100% (26/26), done.\u001b[K\n",
            "remote: Total 276 (delta 11), reused 1 (delta 0), pack-reused 250\u001b[K\n",
            "Receiving objects: 100% (276/276), 2.43 MiB | 10.06 MiB/s, done.\n",
            "Resolving deltas: 100% (116/116), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r /content/PPLM/requirements.txt"
      ],
      "metadata": {
        "id": "dzSrpn5-n-KT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a95a57a6-fb14-4b72-ccda-e9049c4545de"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torch==1.7.0\n",
            "  Downloading torch-1.7.0-cp37-cp37m-manylinux1_x86_64.whl (776.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 776.7 MB 4.1 kB/s \n",
            "\u001b[?25hCollecting nltk==3.4.5\n",
            "  Downloading nltk-3.4.5.zip (1.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.5 MB 62.5 MB/s \n",
            "\u001b[?25hCollecting colorama==0.4.4\n",
            "  Downloading colorama-0.4.4-py2.py3-none-any.whl (16 kB)\n",
            "Collecting transformers==3.4.0\n",
            "  Downloading transformers-3.4.0-py3-none-any.whl (1.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.3 MB 50.4 MB/s \n",
            "\u001b[?25hCollecting torchtext==0.3.1\n",
            "  Downloading torchtext-0.3.1-py3-none-any.whl (62 kB)\n",
            "\u001b[K     |████████████████████████████████| 62 kB 963 kB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch==1.7.0->-r /content/PPLM/requirements.txt (line 1)) (1.19.5)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.7.0->-r /content/PPLM/requirements.txt (line 1)) (3.10.0.2)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from torch==1.7.0->-r /content/PPLM/requirements.txt (line 1)) (0.16.0)\n",
            "Collecting dataclasses\n",
            "  Downloading dataclasses-0.6-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from nltk==3.4.5->-r /content/PPLM/requirements.txt (line 2)) (1.15.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==3.4.0->-r /content/PPLM/requirements.txt (line 4)) (4.62.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==3.4.0->-r /content/PPLM/requirements.txt (line 4)) (2019.12.20)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==3.4.0->-r /content/PPLM/requirements.txt (line 4)) (3.4.0)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers==3.4.0->-r /content/PPLM/requirements.txt (line 4)) (0.0.46)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers==3.4.0->-r /content/PPLM/requirements.txt (line 4)) (21.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==3.4.0->-r /content/PPLM/requirements.txt (line 4)) (2.23.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.7/dist-packages (from transformers==3.4.0->-r /content/PPLM/requirements.txt (line 4)) (3.17.3)\n",
            "Collecting tokenizers==0.9.2\n",
            "  Downloading tokenizers-0.9.2-cp37-cp37m-manylinux1_x86_64.whl (2.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.9 MB 36.1 MB/s \n",
            "\u001b[?25hCollecting sentencepiece!=0.1.92\n",
            "  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 33.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers==3.4.0->-r /content/PPLM/requirements.txt (line 4)) (3.0.6)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.4.0->-r /content/PPLM/requirements.txt (line 4)) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.4.0->-r /content/PPLM/requirements.txt (line 4)) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.4.0->-r /content/PPLM/requirements.txt (line 4)) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.4.0->-r /content/PPLM/requirements.txt (line 4)) (2.10)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==3.4.0->-r /content/PPLM/requirements.txt (line 4)) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==3.4.0->-r /content/PPLM/requirements.txt (line 4)) (1.1.0)\n",
            "Building wheels for collected packages: nltk\n",
            "  Building wheel for nltk (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for nltk: filename=nltk-3.4.5-py3-none-any.whl size=1449921 sha256=6701aa95b994370f874bdf910b0f3032ab4f3e517cb8da8980e34aa46ca90857\n",
            "  Stored in directory: /root/.cache/pip/wheels/48/8b/7f/473521e0c731c6566d631b281f323842bbda9bd819eb9a3ead\n",
            "Successfully built nltk\n",
            "Installing collected packages: dataclasses, torch, tokenizers, sentencepiece, transformers, torchtext, nltk, colorama\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 1.10.0+cu111\n",
            "    Uninstalling torch-1.10.0+cu111:\n",
            "      Successfully uninstalled torch-1.10.0+cu111\n",
            "  Attempting uninstall: tokenizers\n",
            "    Found existing installation: tokenizers 0.10.3\n",
            "    Uninstalling tokenizers-0.10.3:\n",
            "      Successfully uninstalled tokenizers-0.10.3\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.14.1\n",
            "    Uninstalling transformers-4.14.1:\n",
            "      Successfully uninstalled transformers-4.14.1\n",
            "  Attempting uninstall: torchtext\n",
            "    Found existing installation: torchtext 0.11.0\n",
            "    Uninstalling torchtext-0.11.0:\n",
            "      Successfully uninstalled torchtext-0.11.0\n",
            "  Attempting uninstall: nltk\n",
            "    Found existing installation: nltk 3.2.5\n",
            "    Uninstalling nltk-3.2.5:\n",
            "      Successfully uninstalled nltk-3.2.5\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchvision 0.11.1+cu111 requires torch==1.10.0, but you have torch 1.7.0 which is incompatible.\n",
            "torchaudio 0.10.0+cu111 requires torch==1.10.0, but you have torch 1.7.0 which is incompatible.\u001b[0m\n",
            "Successfully installed colorama-0.4.4 dataclasses-0.6 nltk-3.4.5 sentencepiece-0.1.96 tokenizers-0.9.2 torch-1.7.0 torchtext-0.3.1 transformers-3.4.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "class ClassificationHead(torch.nn.Module):\n",
        "    \"\"\"Classification Head for  transformer encoders\"\"\"\n",
        "\n",
        "    def __init__(self, class_size, embed_size):\n",
        "        super(ClassificationHead, self).__init__()\n",
        "        self.class_size = class_size\n",
        "        self.embed_size = embed_size\n",
        "        # self.mlp1 = torch.nn.Linear(embed_size, embed_size)\n",
        "        # self.mlp2 = (torch.nn.Linear(embed_size, class_size))\n",
        "        self.mlp = torch.nn.Linear(embed_size, class_size)\n",
        "\n",
        "    def forward(self, hidden_state):\n",
        "        # hidden_state = F.relu(self.mlp1(hidden_state))\n",
        "        # hidden_state = self.mlp2(hidden_state)\n",
        "        logits = self.mlp(hidden_state)\n",
        "        return logits"
      ],
      "metadata": {
        "id": "VtRdbhDElIa4"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Example command with bag of words:\n",
        "python examples/run_pplm.py -B space --cond_text \"The president\" --length 100 --gamma 1.5 --num_iterations 3 --num_samples 10 --stepsize 0.01 --window_length 5 --kl_scale 0.01 --gm_scale 0.95\n",
        "\n",
        "Example command with discriminator:\n",
        "python examples/run_pplm.py -D sentiment --class_label 3 --cond_text \"The lake\" --length 10 --gamma 1.0 --num_iterations 30 --num_samples 10 --stepsize 0.01 --kl_scale 0.01 --gm_scale 0.95\n",
        "# \"\"\"\n",
        "\n",
        "import argparse\n",
        "import json\n",
        "from operator import add\n",
        "from typing import List, Optional, Tuple, Union\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import Variable\n",
        "from tqdm import trange\n",
        "from transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
        "from transformers.file_utils import cached_path"
      ],
      "metadata": {
        "id": "hbBlKR7qlApq"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "PPLM_BOW = 1\n",
        "PPLM_DISCRIM = 2\n",
        "PPLM_BOW_DISCRIM = 3\n",
        "SMALL_CONST = 1e-15\n",
        "BIG_CONST = 1e10\n",
        "\n",
        "QUIET = 0\n",
        "REGULAR = 1\n",
        "VERBOSE = 2\n",
        "VERY_VERBOSE = 3\n",
        "VERBOSITY_LEVELS = {\n",
        "    'quiet': QUIET,\n",
        "    'regular': REGULAR,\n",
        "    'verbose': VERBOSE,\n",
        "    'very_verbose': VERY_VERBOSE,\n",
        "}\n",
        "\n",
        "base_path = \"/content/gdrive/MyDrive/bow_topics/\"\n",
        "BAG_OF_WORDS_ARCHIVE_MAP = {\n",
        "    'alcohol': base_path+\"alcohol.txt\",\n",
        "    'budget': base_path + \"budget.txt\",\n",
        "    'business': base_path + \"business.txt\",\n",
        "    'crime': base_path + \"crime.txt\",\n",
        "    'defense': base_path + \"defense.txt\",\n",
        "    'economy': base_path +\"economy.txt\",\n",
        "    'education': base_path+\"education.txt\",\n",
        "    'elections': base_path+\"elections.txt\",\n",
        "    'environment': base_path+\"environment.txt\",\n",
        "}\n",
        "\n",
        "DISCRIMINATOR_MODELS_PARAMS = {\n",
        "    \"clickbait\": {\n",
        "        \"url\": \"https://s3.amazonaws.com/models.huggingface.co/bert/pplm/discriminators/clickbait_classifier_head.pt\",\n",
        "        \"class_size\": 2,\n",
        "        \"embed_size\": 1024,\n",
        "        \"class_vocab\": {\"non_clickbait\": 0, \"clickbait\": 1},\n",
        "        \"default_class\": 1,\n",
        "        \"pretrained_model\": \"gpt2-medium\",\n",
        "    },\n",
        "    \"sentiment\": {\n",
        "        \"url\": \"https://s3.amazonaws.com/models.huggingface.co/bert/pplm/discriminators/SST_classifier_head.pt\",\n",
        "        \"class_size\": 5,\n",
        "        \"embed_size\": 1024,\n",
        "        \"class_vocab\": {\"very_positive\": 2, \"very_negative\": 3},\n",
        "        \"default_class\": 3,\n",
        "        \"pretrained_model\": \"gpt2-medium\",\n",
        "    },\n",
        "}\n",
        "\n",
        "\n",
        "def to_var(x, requires_grad=False, volatile=False, device='cuda'):\n",
        "    if torch.cuda.is_available() and device == 'cuda':\n",
        "        x = x.cuda()\n",
        "    elif device != 'cuda':\n",
        "        x = x.to(device)\n",
        "    return Variable(x, requires_grad=requires_grad, volatile=volatile)\n",
        "\n",
        "\n",
        "def top_k_filter(logits, k, probs=False):\n",
        "    \"\"\"\n",
        "    Masks everything but the k top entries as -infinity (1e10).\n",
        "    Used to mask logits such that e^-infinity -> 0 won't contribute to the\n",
        "    sum of the denominator.\n",
        "    \"\"\"\n",
        "    if k == 0:\n",
        "        return logits\n",
        "    else:\n",
        "        values = torch.topk(logits, k)[0]\n",
        "        batch_mins = values[:, -1].view(-1, 1).expand_as(logits)\n",
        "        if probs:\n",
        "            return torch.where(logits < batch_mins,\n",
        "                               torch.ones_like(logits) * 0.0, logits)\n",
        "        return torch.where(logits < batch_mins,\n",
        "                           torch.ones_like(logits) * -BIG_CONST,\n",
        "                           logits)\n",
        "\n",
        "\n",
        "def perturb_past(\n",
        "        past,\n",
        "        model,\n",
        "        last,\n",
        "        unpert_past=None,\n",
        "        unpert_logits=None,\n",
        "        accumulated_hidden=None,\n",
        "        grad_norms=None,\n",
        "        stepsize=0.01,\n",
        "        one_hot_bows_vectors=None,\n",
        "        classifier=None,\n",
        "        class_label=None,\n",
        "        loss_type=0,\n",
        "        num_iterations=3,\n",
        "        horizon_length=1,\n",
        "        window_length=0,\n",
        "        decay=False,\n",
        "        gamma=1.5,\n",
        "        kl_scale=0.01,\n",
        "        device='cuda',\n",
        "        verbosity_level=REGULAR\n",
        "):\n",
        "    # Generate inital perturbed past\n",
        "    grad_accumulator = [\n",
        "        (np.zeros(p.shape).astype(\"float32\"))\n",
        "        for p in past\n",
        "    ]\n",
        "\n",
        "    if accumulated_hidden is None:\n",
        "        accumulated_hidden = 0\n",
        "\n",
        "    if decay:\n",
        "        decay_mask = torch.arange(\n",
        "            0.,\n",
        "            1.0 + SMALL_CONST,\n",
        "            1.0 / (window_length)\n",
        "        )[1:]\n",
        "    else:\n",
        "        decay_mask = 1.0\n",
        "\n",
        "    # Generate a mask is gradient perturbated is based on a past window\n",
        "    _, _, _, curr_length, _ = past[0].shape\n",
        "\n",
        "    if curr_length > window_length and window_length > 0:\n",
        "        ones_key_val_shape = (\n",
        "                tuple(past[0].shape[:-2])\n",
        "                + tuple([window_length])\n",
        "                + tuple(past[0].shape[-1:])\n",
        "        )\n",
        "\n",
        "        zeros_key_val_shape = (\n",
        "                tuple(past[0].shape[:-2])\n",
        "                + tuple([curr_length - window_length])\n",
        "                + tuple(past[0].shape[-1:])\n",
        "        )\n",
        "\n",
        "        ones_mask = torch.ones(ones_key_val_shape)\n",
        "        ones_mask = decay_mask * ones_mask.permute(0, 1, 2, 4, 3)\n",
        "        ones_mask = ones_mask.permute(0, 1, 2, 4, 3)\n",
        "\n",
        "        window_mask = torch.cat(\n",
        "            (ones_mask, torch.zeros(zeros_key_val_shape)),\n",
        "            dim=-2\n",
        "        ).to(device)\n",
        "    else:\n",
        "        window_mask = torch.ones_like(past[0]).to(device)\n",
        "\n",
        "    # accumulate perturbations for num_iterations\n",
        "    loss_per_iter = []\n",
        "    new_accumulated_hidden = None\n",
        "    for i in range(num_iterations):\n",
        "        if verbosity_level >= VERBOSE:\n",
        "            print(\"Iteration \", i + 1)\n",
        "        curr_perturbation = [\n",
        "            to_var(torch.from_numpy(p_), requires_grad=True, device=device)\n",
        "            for p_ in grad_accumulator\n",
        "        ]\n",
        "\n",
        "        # Compute hidden using perturbed past\n",
        "        perturbed_past = list(map(add, past, curr_perturbation))\n",
        "        _, _, _, curr_length, _ = curr_perturbation[0].shape\n",
        "        all_logits, _, all_hidden = model(last, past_key_values=perturbed_past)\n",
        "        hidden = all_hidden[-1]\n",
        "        new_accumulated_hidden = accumulated_hidden + torch.sum(\n",
        "            hidden,\n",
        "            dim=1\n",
        "        ).detach()\n",
        "\n",
        "        logits = all_logits[:, -1, :]\n",
        "        probs = F.softmax(logits, dim=-1)\n",
        "\n",
        "        loss = 0.0\n",
        "        loss_list = []\n",
        "        if loss_type == PPLM_BOW or loss_type == PPLM_BOW_DISCRIM:\n",
        "            for one_hot_bow in one_hot_bows_vectors:\n",
        "                bow_logits = torch.mm(probs, torch.t(one_hot_bow))\n",
        "                bow_loss = -torch.log(torch.sum(bow_logits))\n",
        "                loss += bow_loss\n",
        "                loss_list.append(bow_loss)\n",
        "            if verbosity_level >= VERY_VERBOSE:\n",
        "                print(\" pplm_bow_loss:\", loss.data.cpu().numpy())\n",
        "\n",
        "        if loss_type == PPLM_DISCRIM or loss_type == PPLM_BOW_DISCRIM:\n",
        "            ce_loss = torch.nn.CrossEntropyLoss()\n",
        "            curr_unpert_past = unpert_past\n",
        "            curr_probs = torch.unsqueeze(probs, dim=1)\n",
        "            wte = model.resize_token_embeddings()\n",
        "            for _ in range(horizon_length):\n",
        "                inputs_embeds = torch.matmul(curr_probs, wte.weight.data)\n",
        "                _, curr_unpert_past, curr_all_hidden = model(\n",
        "                    past=curr_unpert_past,\n",
        "                    inputs_embeds=inputs_embeds\n",
        "                )\n",
        "                curr_hidden = curr_all_hidden[-1]\n",
        "                new_accumulated_hidden = new_accumulated_hidden + torch.sum(\n",
        "                    curr_hidden, dim=1)\n",
        "\n",
        "            prediction = classifier(new_accumulated_hidden /\n",
        "                                    (curr_length + 1 + horizon_length))\n",
        "\n",
        "            label = torch.tensor(prediction.shape[0] * [class_label],\n",
        "                                 device=device,\n",
        "                                 dtype=torch.long)\n",
        "            discrim_loss = ce_loss(prediction, label)\n",
        "            if verbosity_level >= VERY_VERBOSE:\n",
        "                print(\" pplm_discrim_loss:\", discrim_loss.data.cpu().numpy())\n",
        "            loss += discrim_loss\n",
        "            loss_list.append(discrim_loss)\n",
        "\n",
        "        kl_loss = 0.0\n",
        "        if kl_scale > 0.0:\n",
        "            unpert_probs = F.softmax(unpert_logits[:, -1, :], dim=-1)\n",
        "            unpert_probs = (\n",
        "                    unpert_probs + SMALL_CONST *\n",
        "                    (unpert_probs <= SMALL_CONST).float().to(device).detach()\n",
        "            )\n",
        "            correction = SMALL_CONST * (probs <= SMALL_CONST).float().to(\n",
        "                device).detach()\n",
        "            corrected_probs = probs + correction.detach()\n",
        "            kl_loss = kl_scale * (\n",
        "                (corrected_probs * (corrected_probs / unpert_probs).log()).sum()\n",
        "            )\n",
        "            if verbosity_level >= VERY_VERBOSE:\n",
        "                print(' kl_loss', kl_loss.data.cpu().numpy())\n",
        "            loss += kl_loss\n",
        "\n",
        "        loss_per_iter.append(loss.data.cpu().numpy())\n",
        "        if verbosity_level >= VERBOSE:\n",
        "            print(' pplm_loss', (loss - kl_loss).data.cpu().numpy())\n",
        "\n",
        "        # compute gradients\n",
        "        loss.backward()\n",
        "\n",
        "        # calculate gradient norms\n",
        "        if grad_norms is not None and loss_type == PPLM_BOW:\n",
        "            grad_norms = [\n",
        "                torch.max(grad_norms[index], torch.norm(p_.grad * window_mask))\n",
        "                for index, p_ in enumerate(curr_perturbation)\n",
        "            ]\n",
        "        else:\n",
        "            grad_norms = [\n",
        "                (torch.norm(p_.grad * window_mask) + SMALL_CONST)\n",
        "                for index, p_ in enumerate(curr_perturbation)\n",
        "            ]\n",
        "\n",
        "        # normalize gradients\n",
        "        grad = [\n",
        "            -stepsize *\n",
        "            (p_.grad * window_mask / grad_norms[\n",
        "                index] ** gamma).data.cpu().numpy()\n",
        "            for index, p_ in enumerate(curr_perturbation)\n",
        "        ]\n",
        "\n",
        "        # accumulate gradient\n",
        "        grad_accumulator = list(map(add, grad, grad_accumulator))\n",
        "\n",
        "        # reset gradients, just to make sure\n",
        "        for p_ in curr_perturbation:\n",
        "            p_.grad.data.zero_()\n",
        "\n",
        "        # removing past from the graph\n",
        "        new_past = []\n",
        "        for p_ in past:\n",
        "            new_past.append(p_.detach())\n",
        "        past = new_past\n",
        "\n",
        "    # apply the accumulated perturbations to the past\n",
        "    grad_accumulator = [\n",
        "        to_var(torch.from_numpy(p_), requires_grad=True, device=device)\n",
        "        for p_ in grad_accumulator\n",
        "    ]\n",
        "    pert_past = list(map(add, past, grad_accumulator))\n",
        "\n",
        "    return pert_past, new_accumulated_hidden, grad_norms, loss_per_iter\n",
        "\n",
        "\n",
        "def get_classifier(\n",
        "        name: Optional[str],\n",
        "        class_label: Union[str, int],\n",
        "        device: str,\n",
        "        verbosity_level: int = REGULAR\n",
        ") -> Tuple[Optional[ClassificationHead], Optional[int]]:\n",
        "    if name is None:\n",
        "        return None, None\n",
        "\n",
        "    params = DISCRIMINATOR_MODELS_PARAMS[name]\n",
        "    classifier = ClassificationHead(\n",
        "        class_size=params['class_size'],\n",
        "        embed_size=params['embed_size']\n",
        "    ).to(device)\n",
        "    if \"url\" in params:\n",
        "        resolved_archive_file = cached_path(params[\"url\"])\n",
        "    elif \"path\" in params:\n",
        "        resolved_archive_file = params[\"path\"]\n",
        "    else:\n",
        "        raise ValueError(\"Either url or path have to be specified \"\n",
        "                         \"in the discriminator model parameters\")\n",
        "    classifier.load_state_dict(\n",
        "        torch.load(resolved_archive_file, map_location=device))\n",
        "    classifier.eval()\n",
        "\n",
        "    if isinstance(class_label, str):\n",
        "        if class_label in params[\"class_vocab\"]:\n",
        "            label_id = params[\"class_vocab\"][class_label]\n",
        "        else:\n",
        "            label_id = params[\"default_class\"]\n",
        "            if verbosity_level >= REGULAR:\n",
        "                print(\"class_label {} not in class_vocab\".format(class_label))\n",
        "                print(\"available values are: {}\".format(params[\"class_vocab\"]))\n",
        "                print(\"using default class {}\".format(label_id))\n",
        "\n",
        "    elif isinstance(class_label, int):\n",
        "        if class_label in set(params[\"class_vocab\"].values()):\n",
        "            label_id = class_label\n",
        "        else:\n",
        "            label_id = params[\"default_class\"]\n",
        "            if verbosity_level >= REGULAR:\n",
        "                print(\"class_label {} not in class_vocab\".format(class_label))\n",
        "                print(\"available values are: {}\".format(params[\"class_vocab\"]))\n",
        "                print(\"using default class {}\".format(label_id))\n",
        "\n",
        "    else:\n",
        "        label_id = params[\"default_class\"]\n",
        "\n",
        "    return classifier, label_id\n",
        "\n",
        "\n",
        "def get_bag_of_words_indices(bag_of_words_ids_or_paths: List[str], tokenizer) -> \\\n",
        "        List[List[List[int]]]:\n",
        "    bow_indices = []\n",
        "    for id_or_path in bag_of_words_ids_or_paths:\n",
        "        if id_or_path in BAG_OF_WORDS_ARCHIVE_MAP:\n",
        "            filepath = cached_path(BAG_OF_WORDS_ARCHIVE_MAP[id_or_path])\n",
        "        else:\n",
        "            filepath = id_or_path\n",
        "        with open(filepath, \"r\") as f:\n",
        "            words = f.read().strip().split(\"\\n\")\n",
        "        bow_indices.append(\n",
        "            [tokenizer.encode(word.strip(),\n",
        "                              add_prefix_space=True,\n",
        "                              add_special_tokens=False)\n",
        "             for word in words])\n",
        "    return bow_indices\n",
        "\n",
        "\n",
        "def build_bows_one_hot_vectors(bow_indices, tokenizer, device='cuda'):\n",
        "    if bow_indices is None:\n",
        "        return None\n",
        "\n",
        "    one_hot_bows_vectors = []\n",
        "    for single_bow in bow_indices:\n",
        "        single_bow = list(filter(lambda x: len(x) <= 1, single_bow))\n",
        "        single_bow = torch.tensor(single_bow).to(device)\n",
        "        num_words = single_bow.shape[0]\n",
        "        one_hot_bow = torch.zeros(num_words, tokenizer.vocab_size).to(device)\n",
        "        one_hot_bow.scatter_(1, single_bow, 1)\n",
        "        one_hot_bows_vectors.append(one_hot_bow)\n",
        "    return one_hot_bows_vectors\n",
        "\n",
        "\n",
        "def full_text_generation(\n",
        "        model,\n",
        "        tokenizer,\n",
        "        context=None,\n",
        "        num_samples=1,\n",
        "        device=\"cuda\",\n",
        "        bag_of_words=None,\n",
        "        discrim=None,\n",
        "        class_label=None,\n",
        "        length=100,\n",
        "        stepsize=0.02,\n",
        "        temperature=1.0,\n",
        "        top_k=10,\n",
        "        sample=True,\n",
        "        num_iterations=3,\n",
        "        grad_length=10000,\n",
        "        horizon_length=1,\n",
        "        window_length=0,\n",
        "        decay=False,\n",
        "        gamma=1.5,\n",
        "        gm_scale=0.9,\n",
        "        kl_scale=0.01,\n",
        "        verbosity_level=REGULAR,\n",
        "        **kwargs\n",
        "):\n",
        "    classifier, class_id = get_classifier(\n",
        "        discrim,\n",
        "        class_label,\n",
        "        device\n",
        "    )\n",
        "\n",
        "    bow_indices = []\n",
        "    if bag_of_words:\n",
        "        bow_indices = get_bag_of_words_indices(bag_of_words.split(\";\"),\n",
        "                                               tokenizer)\n",
        "\n",
        "    if bag_of_words and classifier:\n",
        "        loss_type = PPLM_BOW_DISCRIM\n",
        "        if verbosity_level >= REGULAR:\n",
        "            print(\"Both PPLM-BoW and PPLM-Discrim are on. \"\n",
        "                  \"This is not optimized.\")\n",
        "\n",
        "    elif bag_of_words:\n",
        "        loss_type = PPLM_BOW\n",
        "        if verbosity_level >= REGULAR:\n",
        "            print(\"Using PPLM-BoW\")\n",
        "\n",
        "    elif classifier is not None:\n",
        "        loss_type = PPLM_DISCRIM\n",
        "        if verbosity_level >= REGULAR:\n",
        "            print(\"Using PPLM-Discrim\")\n",
        "\n",
        "    else:\n",
        "        raise Exception(\"Specify either a bag of words or a discriminator\")\n",
        "\n",
        "    unpert_gen_tok_text, _, _ = generate_text_pplm(\n",
        "        model=model,\n",
        "        tokenizer=tokenizer,\n",
        "        context=context,\n",
        "        device=device,\n",
        "        length=length,\n",
        "        sample=sample,\n",
        "        perturb=False,\n",
        "        verbosity_level=verbosity_level\n",
        "    )\n",
        "    if device == 'cuda':\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "    pert_gen_tok_texts = []\n",
        "    discrim_losses = []\n",
        "    losses_in_time = []\n",
        "\n",
        "    for i in range(num_samples):\n",
        "        pert_gen_tok_text, discrim_loss, loss_in_time = generate_text_pplm(\n",
        "            model=model,\n",
        "            tokenizer=tokenizer,\n",
        "            context=context,\n",
        "            device=device,\n",
        "            perturb=True,\n",
        "            bow_indices=bow_indices,\n",
        "            classifier=classifier,\n",
        "            class_label=class_id,\n",
        "            loss_type=loss_type,\n",
        "            length=length,\n",
        "            stepsize=stepsize,\n",
        "            temperature=temperature,\n",
        "            top_k=top_k,\n",
        "            sample=sample,\n",
        "            num_iterations=num_iterations,\n",
        "            grad_length=grad_length,\n",
        "            horizon_length=horizon_length,\n",
        "            window_length=window_length,\n",
        "            decay=decay,\n",
        "            gamma=gamma,\n",
        "            gm_scale=gm_scale,\n",
        "            kl_scale=kl_scale,\n",
        "            verbosity_level=verbosity_level\n",
        "        )\n",
        "        pert_gen_tok_texts.append(pert_gen_tok_text)\n",
        "        if classifier is not None:\n",
        "            discrim_losses.append(discrim_loss.data.cpu().numpy())\n",
        "        losses_in_time.append(loss_in_time)\n",
        "\n",
        "    if device == 'cuda':\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "    return unpert_gen_tok_text, pert_gen_tok_texts, discrim_losses, losses_in_time\n",
        "\n",
        "\n",
        "def generate_text_pplm(\n",
        "        model,\n",
        "        tokenizer,\n",
        "        context=None,\n",
        "        past=None,\n",
        "        device=\"cuda\",\n",
        "        perturb=True,\n",
        "        bow_indices=None,\n",
        "        classifier=None,\n",
        "        class_label=None,\n",
        "        loss_type=0,\n",
        "        length=100,\n",
        "        stepsize=0.02,\n",
        "        temperature=1.0,\n",
        "        top_k=10,\n",
        "        sample=True,\n",
        "        num_iterations=3,\n",
        "        grad_length=10000,\n",
        "        horizon_length=1,\n",
        "        window_length=0,\n",
        "        decay=False,\n",
        "        gamma=1.5,\n",
        "        gm_scale=0.9,\n",
        "        kl_scale=0.01,\n",
        "        verbosity_level=REGULAR\n",
        "):\n",
        "    output_so_far = None\n",
        "    if context:\n",
        "        context_t = torch.tensor(context, device=device, dtype=torch.long)\n",
        "        while len(context_t.shape) < 2:\n",
        "            context_t = context_t.unsqueeze(0)\n",
        "        output_so_far = context_t\n",
        "\n",
        "    # collect one hot vectors for bags of words\n",
        "    one_hot_bows_vectors = build_bows_one_hot_vectors(bow_indices, tokenizer,\n",
        "                                                      device)\n",
        "\n",
        "    grad_norms = None\n",
        "    last = None\n",
        "    unpert_discrim_loss = 0\n",
        "    loss_in_time = []\n",
        "\n",
        "    if verbosity_level >= VERBOSE:\n",
        "        range_func = trange(length, ascii=True)\n",
        "    else:\n",
        "        range_func = range(length)\n",
        "\n",
        "    for i in range_func:\n",
        "\n",
        "        # Get past/probs for current output, except for last word\n",
        "        # Note that GPT takes 2 inputs: past + current_token\n",
        "\n",
        "        # run model forward to obtain unperturbed\n",
        "        if past is None and output_so_far is not None:\n",
        "            last = output_so_far[:, -1:]\n",
        "            if output_so_far.shape[1] > 1:\n",
        "                _, past, _ = model(output_so_far[:, :-1])\n",
        "\n",
        "        unpert_logits, unpert_past, unpert_all_hidden = model(output_so_far)\n",
        "        unpert_last_hidden = unpert_all_hidden[-1]\n",
        "\n",
        "        # check if we are abowe grad max length\n",
        "        if i >= grad_length:\n",
        "            current_stepsize = stepsize * 0\n",
        "        else:\n",
        "            current_stepsize = stepsize\n",
        "\n",
        "        # modify the past if necessary\n",
        "        if not perturb or num_iterations == 0:\n",
        "            pert_past = past\n",
        "\n",
        "        else:\n",
        "            accumulated_hidden = unpert_last_hidden[:, :-1, :]\n",
        "            accumulated_hidden = torch.sum(accumulated_hidden, dim=1)\n",
        "\n",
        "            if past is not None:\n",
        "                pert_past, _, grad_norms, loss_this_iter = perturb_past(\n",
        "                    past,\n",
        "                    model,\n",
        "                    last,\n",
        "                    unpert_past=unpert_past,\n",
        "                    unpert_logits=unpert_logits,\n",
        "                    accumulated_hidden=accumulated_hidden,\n",
        "                    grad_norms=grad_norms,\n",
        "                    stepsize=current_stepsize,\n",
        "                    one_hot_bows_vectors=one_hot_bows_vectors,\n",
        "                    classifier=classifier,\n",
        "                    class_label=class_label,\n",
        "                    loss_type=loss_type,\n",
        "                    num_iterations=num_iterations,\n",
        "                    horizon_length=horizon_length,\n",
        "                    window_length=window_length,\n",
        "                    decay=decay,\n",
        "                    gamma=gamma,\n",
        "                    kl_scale=kl_scale,\n",
        "                    device=device,\n",
        "                    verbosity_level=verbosity_level\n",
        "                )\n",
        "                loss_in_time.append(loss_this_iter)\n",
        "            else:\n",
        "                pert_past = past\n",
        "\n",
        "        pert_logits, past, pert_all_hidden = model(last, past=pert_past)\n",
        "        pert_logits = pert_logits[:, -1, :] / temperature  # + SMALL_CONST\n",
        "        pert_probs = F.softmax(pert_logits, dim=-1)\n",
        "\n",
        "        if classifier is not None:\n",
        "            ce_loss = torch.nn.CrossEntropyLoss()\n",
        "            prediction = classifier(torch.mean(unpert_last_hidden, dim=1))\n",
        "            label = torch.tensor([class_label], device=device,\n",
        "                                 dtype=torch.long)\n",
        "            unpert_discrim_loss = ce_loss(prediction, label)\n",
        "            if verbosity_level >= VERBOSE:\n",
        "                print(\n",
        "                    \"unperturbed discrim loss\",\n",
        "                    unpert_discrim_loss.data.cpu().numpy()\n",
        "                )\n",
        "        else:\n",
        "            unpert_discrim_loss = 0\n",
        "\n",
        "        # Fuse the modified model and original model\n",
        "        if perturb:\n",
        "\n",
        "            unpert_probs = F.softmax(unpert_logits[:, -1, :], dim=-1)\n",
        "\n",
        "            pert_probs = ((pert_probs ** gm_scale) * (\n",
        "                    unpert_probs ** (1 - gm_scale)))  # + SMALL_CONST\n",
        "            pert_probs = top_k_filter(pert_probs, k=top_k,\n",
        "                                      probs=True)  # + SMALL_CONST\n",
        "\n",
        "            # rescale\n",
        "            if torch.sum(pert_probs) <= 1:\n",
        "                pert_probs = pert_probs / torch.sum(pert_probs)\n",
        "\n",
        "        else:\n",
        "            pert_logits = top_k_filter(pert_logits, k=top_k)  # + SMALL_CONST\n",
        "            pert_probs = F.softmax(pert_logits, dim=-1)\n",
        "\n",
        "        # sample or greedy\n",
        "        if sample:\n",
        "            last = torch.multinomial(pert_probs, num_samples=1)\n",
        "\n",
        "        else:\n",
        "            _, last = torch.topk(pert_probs, k=1, dim=-1)\n",
        "\n",
        "        # update context/output_so_far appending the new token\n",
        "        output_so_far = (\n",
        "            last if output_so_far is None\n",
        "            else torch.cat((output_so_far, last), dim=1)\n",
        "        )\n",
        "        if verbosity_level >= REGULAR:\n",
        "            print(tokenizer.decode(output_so_far.tolist()[0]))\n",
        "\n",
        "    return output_so_far, unpert_discrim_loss, loss_in_time\n",
        "\n",
        "\n",
        "def set_generic_model_params(discrim_weights, discrim_meta):\n",
        "    if discrim_weights is None:\n",
        "        raise ValueError('When using a generic discriminator, '\n",
        "                         'discrim_weights need to be specified')\n",
        "    if discrim_meta is None:\n",
        "        raise ValueError('When using a generic discriminator, '\n",
        "                         'discrim_meta need to be specified')\n",
        "\n",
        "    with open(discrim_meta, 'r') as discrim_meta_file:\n",
        "        meta = json.load(discrim_meta_file)\n",
        "    meta['path'] = discrim_weights\n",
        "    DISCRIMINATOR_MODELS_PARAMS['generic'] = meta\n",
        "\n",
        "\n",
        "def run_pplm_example(\n",
        "        pretrained_model=\"gpt2-medium\",\n",
        "        cond_text=\"\",\n",
        "        uncond=False,\n",
        "        num_samples=1,\n",
        "        bag_of_words=None,\n",
        "        discrim=None,\n",
        "        discrim_weights=None,\n",
        "        discrim_meta=None,\n",
        "        class_label=-1,\n",
        "        length=100,\n",
        "        stepsize=0.02,\n",
        "        temperature=1.0,\n",
        "        top_k=10,\n",
        "        sample=True,\n",
        "        num_iterations=3,\n",
        "        grad_length=10000,\n",
        "        horizon_length=1,\n",
        "        window_length=0,\n",
        "        decay=False,\n",
        "        gamma=1.5,\n",
        "        gm_scale=0.9,\n",
        "        kl_scale=0.01,\n",
        "        seed=0,\n",
        "        no_cuda=False,\n",
        "        colorama=False,\n",
        "        verbosity='regular'\n",
        "):\n",
        "    # set Random seed\n",
        "    torch.manual_seed(seed)\n",
        "    np.random.seed(seed)\n",
        "\n",
        "    # set verbosiry\n",
        "    verbosity_level = VERBOSITY_LEVELS.get(verbosity.lower(), REGULAR)\n",
        "\n",
        "    # set the device\n",
        "    device = \"cuda\" if torch.cuda.is_available() and not no_cuda else \"cpu\"\n",
        "\n",
        "    if discrim == 'generic':\n",
        "        set_generic_model_params(discrim_weights, discrim_meta)\n",
        "\n",
        "    if discrim is not None:\n",
        "        discriminator_pretrained_model = DISCRIMINATOR_MODELS_PARAMS[discrim][\n",
        "            \"pretrained_model\"\n",
        "        ]\n",
        "        if pretrained_model != discriminator_pretrained_model:\n",
        "            pretrained_model = discriminator_pretrained_model\n",
        "            if verbosity_level >= REGULAR:\n",
        "                print(\"discrim = {}, pretrained_model set \"\n",
        "                \"to discriminator's = {}\".format(discrim, pretrained_model))\n",
        "\n",
        "    # load pretrained model\n",
        "    model = GPT2LMHeadModel.from_pretrained(\n",
        "        \"gpt2\",\n",
        "        output_hidden_states=True\n",
        "    )\n",
        "    drive_path ='/content/gdrive/MyDrive/model_no_trunc.pt'\n",
        "    model.load_state_dict(torch.load(drive_path))\n",
        "\n",
        "    model.to(device)\n",
        "    model.eval()\n",
        "\n",
        "    # load tokenizer\n",
        "    tokenizer = GPT2Tokenizer.from_pretrained(pretrained_model)\n",
        "\n",
        "    # Freeze GPT-2 weights\n",
        "    for param in model.parameters():\n",
        "        param.requires_grad = False\n",
        "\n",
        "    # figure out conditioning text\n",
        "    if uncond:\n",
        "        tokenized_cond_text = tokenizer.encode(\n",
        "            [tokenizer.bos_token],\n",
        "            add_special_tokens=False\n",
        "        )\n",
        "    else:\n",
        "        raw_text = cond_text\n",
        "        while not raw_text:\n",
        "            print(\"Did you forget to add `--cond_text`? \")\n",
        "            raw_text = input(\"Model prompt >>> \")\n",
        "        tokenized_cond_text = tokenizer.encode(\n",
        "            tokenizer.bos_token + raw_text,\n",
        "            add_special_tokens=False\n",
        "        )\n",
        "\n",
        "    print(\"= Prefix of sentence =\")\n",
        "    print(tokenizer.decode(tokenized_cond_text))\n",
        "    print()\n",
        "\n",
        "    # generate unperturbed and perturbed texts\n",
        "\n",
        "    # full_text_generation returns:\n",
        "    # unpert_gen_tok_text, pert_gen_tok_texts, discrim_losses, losses_in_time\n",
        "    unpert_gen_tok_text, pert_gen_tok_texts, _, _ = full_text_generation(\n",
        "        model=model,\n",
        "        tokenizer=tokenizer,\n",
        "        context=tokenized_cond_text,\n",
        "        device=device,\n",
        "        num_samples=num_samples,\n",
        "        bag_of_words=bag_of_words,\n",
        "        discrim=discrim,\n",
        "        class_label=class_label,\n",
        "        length=length,\n",
        "        stepsize=stepsize,\n",
        "        temperature=temperature,\n",
        "        top_k=top_k,\n",
        "        sample=sample,\n",
        "        num_iterations=num_iterations,\n",
        "        grad_length=grad_length,\n",
        "        horizon_length=horizon_length,\n",
        "        window_length=window_length,\n",
        "        decay=decay,\n",
        "        gamma=gamma,\n",
        "        gm_scale=gm_scale,\n",
        "        kl_scale=kl_scale,\n",
        "        verbosity_level=verbosity_level\n",
        "    )\n",
        "\n",
        "    # untokenize unperturbed text\n",
        "    generated_text_=[]\n",
        "    unpert_gen_text = tokenizer.decode(unpert_gen_tok_text.tolist()[0])\n",
        "\n",
        "    if verbosity_level >= REGULAR:\n",
        "        print(\"=\" * 80)\n",
        "    print(\"= Unperturbed generated text =\")\n",
        "    print(unpert_gen_text)\n",
        "    # generated_text_.append(unpert_gen_text)\n",
        "    print()\n",
        "\n",
        "    generated_texts = []\n",
        "\n",
        "    bow_word_ids = set()\n",
        "    if bag_of_words and colorama:\n",
        "        bow_indices = get_bag_of_words_indices(bag_of_words.split(\";\"),\n",
        "                                               tokenizer)\n",
        "        for single_bow_list in bow_indices:\n",
        "            # filtering all words in the list composed of more than 1 token\n",
        "            filtered = list(filter(lambda x: len(x) <= 1, single_bow_list))\n",
        "            # w[0] because we are sure w has only 1 item because previous fitler\n",
        "            bow_word_ids.update(w[0] for w in filtered)\n",
        "\n",
        "    # iterate through the perturbed texts\n",
        "    for i, pert_gen_tok_text in enumerate(pert_gen_tok_texts):\n",
        "        try:\n",
        "            # untokenize unperturbed text\n",
        "            if colorama:\n",
        "                import colorama\n",
        "\n",
        "                pert_gen_text = ''\n",
        "                for word_id in pert_gen_tok_text.tolist()[0]:\n",
        "                    if word_id in bow_word_ids:\n",
        "                        pert_gen_text += '{}{}{}'.format(\n",
        "                            colorama.Fore.RED,\n",
        "                            tokenizer.decode([word_id]),\n",
        "                            colorama.Style.RESET_ALL\n",
        "                        )\n",
        "                    else:\n",
        "                        pert_gen_text += tokenizer.decode([word_id])\n",
        "            else:\n",
        "                pert_gen_text = tokenizer.decode(pert_gen_tok_text.tolist()[0])\n",
        "\n",
        "            print(\"= Perturbed generated text {} =\".format(i + 1))\n",
        "            print(pert_gen_text)\n",
        "            generated_text_.append(pert_gen_text)\n",
        "            print()\n",
        "        except:\n",
        "            pass\n",
        "\n",
        "        # keep the prefix, perturbed seq, original seq for each index\n",
        "        generated_texts.append(\n",
        "            (tokenized_cond_text, pert_gen_tok_text, unpert_gen_tok_text)\n",
        "        )\n",
        "\n",
        "    return generated_text_\n",
        "\n"
      ],
      "metadata": {
        "id": "lmyY30VW0H4_"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate prompts\n",
        "import pandas as pd\n",
        "ten_df = pd.read_csv(\"/content/additional_prompts.csv\")\n",
        "twenty_df = pd.read_csv(\"/content/gdrive/MyDrive/pplm_approach2_generated_text_thirty_economy.csv\")\n",
        "twenty_df.drop_duplicates(inplace=True)\n",
        "twenty_df.columns = [\"prompt\", \"speech\"]\n",
        "total_prompts = ten_df[\"prompt\"].append(twenty_df[\"prompt\"])"
      ],
      "metadata": {
        "id": "ZOvmHlnjj86V"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "list_generated_text = []\n",
        "with open(\"/content/gdrive/MyDrive/pplm_approach2_stepsize.csv\", \"a+\") as csvfile:\n",
        "  csvwriter = csv.writer(csvfile)\n",
        "  for prompt in total_prompts:\n",
        "    generated_text_pplm = run_pplm_example(\n",
        "        cond_text=prompt,\n",
        "        num_samples=1,\n",
        "        bag_of_words=\"economy\",\n",
        "        discrim='generic',\n",
        "        discrim_meta=\"/content/gdrive/MyDrive/generic_classifier_head_meta.json\",\n",
        "        discrim_weights=\"/content/gdrive/MyDrive/generic_classifier_head_epoch_5.pt\",\n",
        "        class_label=0,\n",
        "        length=100,\n",
        "        stepsize=0.01,\n",
        "        sample=True,\n",
        "        num_iterations=3,\n",
        "        window_length=5,\n",
        "        gamma=1.5,\n",
        "        gm_scale=0.95,\n",
        "        kl_scale=0.01,\n",
        "        verbosity='quiet'\n",
        "    )\n",
        "    list_generated_text.append(pd.Series([prompt, generated_text_pplm]))\n",
        "    csvwriter.writerows(list_generated_text)"
      ],
      "metadata": {
        "id": "c1MBnfrukRcd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4325ad7b-e818-44f7-ff97-b817ffc84a2e"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "= Prefix of sentence =\n",
            "<|endoftext|>I stand here today humbled by the task before us, grateful for the trust you have bestowed,\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/modeling_gpt2.py:759: FutureWarning: The `past` argument is deprecated and will be removed in a future version, use `past_key_values` instead.\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "= Unperturbed generated text =\n",
            "<|endoftext|>I stand here today humbled by the task before us, grateful for the trust you have bestowed, and grateful to your continued support.\n",
            "\n",
            "We must be united in our efforts to make sure that our nation and its people will have a strong and prosperous future for generations to come.\n",
            "\n",
            "I will continue to urge my colleagues to keep our commitment to the Constitution and the laws of the United States. We must do all we can to preserve our freedoms.\n",
            "\n",
            "I will address the nation today in support of the resolution that I passed in support of our nation's efforts to repeal the Affordable Care\n",
            "\n",
            "= Perturbed generated text 1 =\n",
            "<|endoftext|>I stand here today humbled by the task before us, grateful for the trust you have bestowed, and grateful that we are now able to offer the first and only opportunity to a member of the U.S. Congress.<|endoftext|>I was born and raised in New York City. I grew up in a small town called New York City that is home to one of the best schools in America. My mother was a lawyer in the private sector for several decades. I grew up in rural and urban businesses. my dad worked on finance, real estate. and business loans. my business interests included investment banking\n",
            "\n",
            "= Prefix of sentence =\n",
            "<|endoftext|>Today I say to you that the challenges we face are real.\n",
            "\n",
            "= Unperturbed generated text =\n",
            "<|endoftext|>Today I say to you that the challenges we face are real. Our nation faces the greatest challenge in the history of mankind. But we are not going to let it get to us. We will have to take a hard look at what is going on.\n",
            "\n",
            "First of all we must understand that we have a very serious problem in our country. Our economy is in recession. The deficit is $16.8 trillion. and our deficit is at $14.6 trillion. We are not spending enough to keep up with inflation. We are not cutting spending enough\n",
            "\n",
            "= Perturbed generated text 1 =\n",
            "<|endoftext|>Today I say to you that the challenges we face are real. But they are not just real. They are the reality.\n",
            "\n",
            "We have a great country. we have some wonderful people and some great people who have been in our government for a long time. but they are not just the people that we have elected. and that is what the real estate business is about. the real estate business is not just business. it is also business business and business business business business business and. $ \".\n",
            ". $\n",
            "\n",
            "\n",
            "\n",
            ". $\n",
            "\n",
            ",\n",
            "\n",
            "= Prefix of sentence =\n",
            "<|endoftext|>I want to thank my partner in this journey\n",
            "\n",
            "= Unperturbed generated text =\n",
            "<|endoftext|>I want to thank my partner in this journey. I am so grateful for your support. I will be going on a cruise to the Bahamas in October. My first day will be a long one. As I said, I am a long term travel enthusiast. I travel all day. I love the ocean, but my heart is full of sadness. When I am on vacation, I have the feeling that my body is going to be damaged by this trip. But my body is a bit better when I am on vacation. I have a good\n",
            "\n",
            "= Perturbed generated text 1 =\n",
            "<|endoftext|>I want to thank my partner in this journey. I want to thank myself. I want to thank everyone. I want to thank my family. I want to thank my community. I also want to acknowledge the men of my profession. the women that have given up work. and the business that is my own.\n",
            "\n",
            "So let me start with the money. The most important part of my business is my business. business is business. business is business. business is business. business is business business business business company business business company business company company\n",
            "\n",
            "= Prefix of sentence =\n",
            "<|endoftext|>I welcome you all to this grand event\n",
            "\n",
            "= Unperturbed generated text =\n",
            "<|endoftext|>I welcome you all to this grand event. I am honored to host a celebration of the work of the New Jersey Historical Society. This year we will be hosting a \"Historical Festival of Honor\" for the museum. We will take the opportunity to present our museum collection. we will be hosting a celebration of the work of the New Jersey Historical Society.\n",
            "\n",
            "I am also pleased I will bring a few more details about the museum. this is going to take place on a special occasion. we will be giving the annual \"Historic\n",
            "\n",
            "= Perturbed generated text 1 =\n",
            "<|endoftext|>I welcome you all to this grand event. I will be hosting a grand prize event at the hotel. the grand prize award. I will be awarding the prize money to the hotel and the guests. if you are lucky to be there. and have a job. the hotel will be providing food, services and accommodations for the guests. the hotel will provide services in the business sector for the business owners.\n",
            "\n",
            "I am also a business owner. business owner. business owner. business owner. business owner. business owner. business owner.\n",
            "\n",
            "= Prefix of sentence =\n",
            "<|endoftext|>Good morning, ladies and gentlemen\n",
            "\n",
            "= Unperturbed generated text =\n",
            "<|endoftext|>Good morning, ladies and gentlemen. Today marks the 50th anniversary of our founding, with a celebration of our first year together in San Antonio and with a special celebration for women. Our first night of dancing. the first night we were there. our first time. we were there for the first time as members of the women's club. our first dance together. we celebrated our first time in a club. in the first year of our club. we had a special event for the first time. it was in the city of\n",
            "\n",
            "= Perturbed generated text 1 =\n",
            "<|endoftext|>Good morning, ladies and gentlemen. Welcome to another installment of the \"Podcast for everyone!\" series. Today I would like to address the current and past issues with the use of the word \"taxpayer.\" We all know that \"taxpayer\" is the word that is used to describe the private sector. It is not the government itself. The government does not pay for itself. The government does not take money and spend it on businesses or capital stock. the government does not invest capital capital. it has capital stock. capital\n",
            "\n",
            "= Prefix of sentence =\n",
            "<|endoftext|>My name is Mark Dorsey, and I em elated to stand before you\n",
            "\n",
            "= Unperturbed generated text =\n",
            "<|endoftext|>My name is Mark Dorsey, and I em elated to stand before you. You may remember me for your work in the media during your time as a senator from Rhode Island and as an early member of the press corps. I have been working for a number of years on your behalf. I have been a senior adviser to the senator, and as a member of the board of directors at the university of Rhode Island. I was the chair of the university's board of trustees in 2004. I was also a member of the senate's subcommittee on health and human services. In\n",
            "\n",
            "= Perturbed generated text 1 =\n",
            "<|endoftext|>My name is Mark Dorsey, and I em elated to stand before you today on the steps of the Capitol building in Washington. As you know, we have been in the Senate since 1976 and have been working on legislation to protect Americans from the dangers of the financial crisis. But this week we will also have a big debate about immigration and national security issues with an important ally. the United States of America. which has been in business from the start and is now a leading oil refining company. i.e. oil refinery oil company. oil refinery oil company oil refinery oil\n",
            "\n",
            "= Prefix of sentence =\n",
            "<|endoftext|>I dream of a world where we have pride in our country\n",
            "\n",
            "= Unperturbed generated text =\n",
            "<|endoftext|>I dream of a world where we have pride in our country. I dream of a place where the country has become the country of pride. And the pride in our country is not a result of a foreign policy. It is a consequence of the way our country has been run in decades of political and economic turmoil.\n",
            "\n",
            "As a senator from New Jersey from 2004 to 2008, I voted against a measure that would have made it easier for corporations to sue the federal government over its role in the 2008 financial meltdown. Senator McCain voted for the legislation after hearing testimony\n",
            "\n",
            "= Perturbed generated text 1 =\n",
            "<|endoftext|>I dream of a world where we have pride in our country's history.\n",
            "\n",
            "And we have pride in our nation's history.\n",
            "\n",
            "The country of our birth. The country we grew up in.\n",
            "\n",
            "The country of our birth.\n",
            "\n",
            "But what about our heritage?\n",
            "\n",
            "Our heritage is in the oil industry.\n",
            "\n",
            "We know oil companies are big businesses\n",
            "\n",
            "we know oil industry is a business\n",
            "\n",
            "so we can invest in this company and invest in the oil industry.\n",
            "\n",
            "Oil oil refinery. oil oil refinery oil\n",
            "\n",
            "= Prefix of sentence =\n",
            "<|endoftext|>We must be united to end racism as well as gender inequality\n",
            "\n",
            "= Unperturbed generated text =\n",
            "<|endoftext|>We must be united to end racism as well as gender inequality.\n",
            "\n",
            "This election has been the most divisive in our country's history. And while we are united in calling for a real change that will benefit all of our citizens, our leaders must take the time to understand our concerns.\n",
            "\n",
            "It is time for us to address the underlying causes of inequality. We must take on all forms of discrimination. We must confront racism. We must confront sexism.\n",
            "\n",
            "We must take action to ensure the rights and dignity of all women. But we must also\n",
            "\n",
            "= Perturbed generated text 1 =\n",
            "<|endoftext|>We must be united to end racism as well as gender inequality.\n",
            "\n",
            "We are united in calling upon the leadership of the national security council to support the efforts of the united states.<|endoftext|>The \"black blocs\" will be able to vote for the party that is most closely aligned with white supremacy.\n",
            "\n",
            "The president's chief financial officer is a former Goldman Sachs executive who is a major player in the energy industry.\n",
            "\n",
            "\"They have a strong relationship to the oil and gas industry.\"\n",
            "\n",
            "The company that is making oil and gas company profits\n",
            "\n",
            "= Prefix of sentence =\n",
            "<|endoftext|>I want to start by congratulating Laurel on her victory tonight\n",
            "\n",
            "= Unperturbed generated text =\n",
            "<|endoftext|>I want to start by congratulating Laurel on her victory tonight. She has been a fantastic leader for so many years with her team. She is the first woman coach to play with a woman in the women's soccer league for the first time. Her leadership skills will be a huge part of her future. She is also the first woman to represent the women's soccer league at a tournament. She has been the first female coach to take a game off of a game and take the first women's soccer match in the history of the women's football program. She\n",
            "\n",
            "= Perturbed generated text 1 =\n",
            "<|endoftext|>I want to start by congratulating Laurel on her victory tonight. She did a great job tonight and was the first lady to have the honor of serving in the U.S. House and Senate. She has been a true leader of the nation. she has a lot to offer people. she is the best example we have for people who have an income gap and are struggling to make ends meet.\"<|endoftext|>The world's second biggest producer of consumer and financial services is facing record capital gains tax ( FATCA ) of 2.4 per cent in the year ended\n",
            "\n",
            "= Prefix of sentence =\n",
            "<|endoftext|>What a day to be alive\n",
            "\n",
            "= Unperturbed generated text =\n",
            "<|endoftext|>What a day to be alive.\n",
            "\n",
            "This year's \"Survivor: Game Change\" season is shaping up to be one of the biggest.\n",
            "\n",
            "In the first round of the season, two of the top four contestants are coming back strong.\n",
            "\n",
            "Tami and Sam, who have competed in two of the top five seasons of Survivor, are now facing off again.\n",
            "\n",
            "Both are in the first round of the new season, where they'll be playing the game of life for the first time.\n",
            "\n",
            "\n",
            "= Perturbed generated text 1 =\n",
            "<|endoftext|>What a day to be alive.\n",
            "\n",
            "I'm a former high school basketball star and college basketball writer. I've been in politics for almost 40 years and am currently president of the University of Virginia's Board of Regents.\n",
            "\n",
            "I recently took the time to speak with the president of the college basketball business owners association to discuss the business side of basketball and why they are investing heavily in basketball.\n",
            "\n",
            "\"I think the business side of basketball is the most important business of business and sports business. It provides the business\n",
            "\n",
            "= Prefix of sentence =\n",
            "<|endoftext|>I stand here today humbled by the task before us, grateful for the trust you have bestowed,\n",
            "\n",
            "= Unperturbed generated text =\n",
            "<|endoftext|>I stand here today humbled by the task before us, grateful for the trust you have bestowed, and grateful to your continued support.\n",
            "\n",
            "We must be united in our efforts to make sure that our nation and its people will have a strong and prosperous future for generations to come.\n",
            "\n",
            "I will continue to urge my colleagues to keep our commitment to the Constitution and the laws of the United States. We must do all we can to preserve our freedoms.\n",
            "\n",
            "I will address the nation today in support of the resolution that I passed in support of our nation's efforts to repeal the Affordable Care\n",
            "\n",
            "= Perturbed generated text 1 =\n",
            "<|endoftext|>I stand here today humbled by the task before us, grateful for the trust you have bestowed, and grateful that we are now able to offer the first and only opportunity to a member of the U.S. Congress.<|endoftext|>I was born and raised in New York City. I grew up in a small town called New York City that is home to one of the best schools in America. My mother was a lawyer in the private sector for several decades. I grew up in rural and urban businesses. my dad worked on finance, real estate. and business loans. my business interests included investment banking\n",
            "\n",
            "= Prefix of sentence =\n",
            "<|endoftext|>Today I say to you that the challenges we face are real.\n",
            "\n",
            "= Unperturbed generated text =\n",
            "<|endoftext|>Today I say to you that the challenges we face are real. Our nation faces the greatest challenge in the history of mankind. But we are not going to let it get to us. We will have to take a hard look at what is going on.\n",
            "\n",
            "First of all we must understand that we have a very serious problem in our country. Our economy is in recession. The deficit is $16.8 trillion. and our deficit is at $14.6 trillion. We are not spending enough to keep up with inflation. We are not cutting spending enough\n",
            "\n",
            "= Perturbed generated text 1 =\n",
            "<|endoftext|>Today I say to you that the challenges we face are real. But they are not just real. They are the reality.\n",
            "\n",
            "We have a great country. we have some wonderful people and some great people who have been in our government for a long time. but they are not just the people that we have elected. and that is what the real estate business is about. the real estate business is not just business. it is also business business and business business business business business and. $ \".\n",
            ". $\n",
            "\n",
            "\n",
            "\n",
            ". $\n",
            "\n",
            ",\n",
            "\n",
            "= Prefix of sentence =\n",
            "<|endoftext|>I want to thank my partner in this journey\n",
            "\n",
            "= Unperturbed generated text =\n",
            "<|endoftext|>I want to thank my partner in this journey. I am so grateful for your support. I will be going on a cruise to the Bahamas in October. My first day will be a long one. As I said, I am a long term travel enthusiast. I travel all day. I love the ocean, but my heart is full of sadness. When I am on vacation, I have the feeling that my body is going to be damaged by this trip. But my body is a bit better when I am on vacation. I have a good\n",
            "\n",
            "= Perturbed generated text 1 =\n",
            "<|endoftext|>I want to thank my partner in this journey. I want to thank myself. I want to thank everyone. I want to thank my family. I want to thank my community. I also want to acknowledge the men of my profession. the women that have given up work. and the business that is my own.\n",
            "\n",
            "So let me start with the money. The most important part of my business is my business. business is business. business is business. business is business. business is business business business business company business business company business company company\n",
            "\n",
            "= Prefix of sentence =\n",
            "<|endoftext|>I welcome you all to this grand event\n",
            "\n",
            "= Unperturbed generated text =\n",
            "<|endoftext|>I welcome you all to this grand event. I am honored to host a celebration of the work of the New Jersey Historical Society. This year we will be hosting a \"Historical Festival of Honor\" for the museum. We will take the opportunity to present our museum collection. we will be hosting a celebration of the work of the New Jersey Historical Society.\n",
            "\n",
            "I am also pleased I will bring a few more details about the museum. this is going to take place on a special occasion. we will be giving the annual \"Historic\n",
            "\n",
            "= Perturbed generated text 1 =\n",
            "<|endoftext|>I welcome you all to this grand event. I will be hosting a grand prize event at the hotel. the grand prize award. I will be awarding the prize money to the hotel and the guests. if you are lucky to be there. and have a job. the hotel will be providing food, services and accommodations for the guests. the hotel will provide services in the business sector for the business owners.\n",
            "\n",
            "I am also a business owner. business owner. business owner. business owner. business owner. business owner. business owner.\n",
            "\n",
            "= Prefix of sentence =\n",
            "<|endoftext|>Good morning, ladies and gentlemen\n",
            "\n",
            "= Unperturbed generated text =\n",
            "<|endoftext|>Good morning, ladies and gentlemen. Today marks the 50th anniversary of our founding, with a celebration of our first year together in San Antonio and with a special celebration for women. Our first night of dancing. the first night we were there. our first time. we were there for the first time as members of the women's club. our first dance together. we celebrated our first time in a club. in the first year of our club. we had a special event for the first time. it was in the city of\n",
            "\n",
            "= Perturbed generated text 1 =\n",
            "<|endoftext|>Good morning, ladies and gentlemen. Welcome to another installment of the \"Podcast for everyone!\" series. Today I would like to address the current and past issues with the use of the word \"taxpayer.\" We all know that \"taxpayer\" is the word that is used to describe the private sector. It is not the government itself. The government does not pay for itself. The government does not take money and spend it on businesses or capital stock. the government does not invest capital capital. it has capital stock. capital\n",
            "\n",
            "= Prefix of sentence =\n",
            "<|endoftext|>My name is Mark Dorsey, and I em elated to stand before you\n",
            "\n",
            "= Unperturbed generated text =\n",
            "<|endoftext|>My name is Mark Dorsey, and I em elated to stand before you. You may remember me for your work in the media during your time as a senator from Rhode Island and as an early member of the press corps. I have been working for a number of years on your behalf. I have been a senior adviser to the senator, and as a member of the board of directors at the university of Rhode Island. I was the chair of the university's board of trustees in 2004. I was also a member of the senate's subcommittee on health and human services. In\n",
            "\n",
            "= Perturbed generated text 1 =\n",
            "<|endoftext|>My name is Mark Dorsey, and I em elated to stand before you today on the steps of the Capitol building in Washington. As you know, we have been in the Senate since 1976 and have been working on legislation to protect Americans from the dangers of the financial crisis. But this week we will also have a big debate about immigration and national security issues with an important ally. the United States of America. which has been in business from the start and is now a leading oil refining company. i.e. oil refinery oil company. oil refinery oil company oil refinery oil\n",
            "\n",
            "= Prefix of sentence =\n",
            "<|endoftext|>I dream of a world where we have pride in our country\n",
            "\n",
            "= Unperturbed generated text =\n",
            "<|endoftext|>I dream of a world where we have pride in our country. I dream of a place where the country has become the country of pride. And the pride in our country is not a result of a foreign policy. It is a consequence of the way our country has been run in decades of political and economic turmoil.\n",
            "\n",
            "As a senator from New Jersey from 2004 to 2008, I voted against a measure that would have made it easier for corporations to sue the federal government over its role in the 2008 financial meltdown. Senator McCain voted for the legislation after hearing testimony\n",
            "\n",
            "= Perturbed generated text 1 =\n",
            "<|endoftext|>I dream of a world where we have pride in our country's history.\n",
            "\n",
            "And we have pride in our nation's history.\n",
            "\n",
            "The country of our birth. The country we grew up in.\n",
            "\n",
            "The country of our birth.\n",
            "\n",
            "But what about our heritage?\n",
            "\n",
            "Our heritage is in the oil industry.\n",
            "\n",
            "We know oil companies are big businesses\n",
            "\n",
            "we know oil industry is a business\n",
            "\n",
            "so we can invest in this company and invest in the oil industry.\n",
            "\n",
            "Oil oil refinery. oil oil refinery oil\n",
            "\n",
            "= Prefix of sentence =\n",
            "<|endoftext|>We must be united to end racism as well as gender inequality\n",
            "\n",
            "= Unperturbed generated text =\n",
            "<|endoftext|>We must be united to end racism as well as gender inequality.\n",
            "\n",
            "This election has been the most divisive in our country's history. And while we are united in calling for a real change that will benefit all of our citizens, our leaders must take the time to understand our concerns.\n",
            "\n",
            "It is time for us to address the underlying causes of inequality. We must take on all forms of discrimination. We must confront racism. We must confront sexism.\n",
            "\n",
            "We must take action to ensure the rights and dignity of all women. But we must also\n",
            "\n",
            "= Perturbed generated text 1 =\n",
            "<|endoftext|>We must be united to end racism as well as gender inequality.\n",
            "\n",
            "We are united in calling upon the leadership of the national security council to support the efforts of the united states.<|endoftext|>The \"black blocs\" will be able to vote for the party that is most closely aligned with white supremacy.\n",
            "\n",
            "The president's chief financial officer is a former Goldman Sachs executive who is a major player in the energy industry.\n",
            "\n",
            "\"They have a strong relationship to the oil and gas industry.\"\n",
            "\n",
            "The company that is making oil and gas company profits\n",
            "\n",
            "= Prefix of sentence =\n",
            "<|endoftext|>I want to start by congratulating Laurel on her victory tonight\n",
            "\n",
            "= Unperturbed generated text =\n",
            "<|endoftext|>I want to start by congratulating Laurel on her victory tonight. She has been a fantastic leader for so many years with her team. She is the first woman coach to play with a woman in the women's soccer league for the first time. Her leadership skills will be a huge part of her future. She is also the first woman to represent the women's soccer league at a tournament. She has been the first female coach to take a game off of a game and take the first women's soccer match in the history of the women's football program. She\n",
            "\n",
            "= Perturbed generated text 1 =\n",
            "<|endoftext|>I want to start by congratulating Laurel on her victory tonight. She did a great job tonight and was the first lady to have the honor of serving in the U.S. House and Senate. She has been a true leader of the nation. she has a lot to offer people. she is the best example we have for people who have an income gap and are struggling to make ends meet.\"<|endoftext|>The world's second biggest producer of consumer and financial services is facing record capital gains tax ( FATCA ) of 2.4 per cent in the year ended\n",
            "\n",
            "= Prefix of sentence =\n",
            "<|endoftext|>What a day to be alive\n",
            "\n",
            "= Unperturbed generated text =\n",
            "<|endoftext|>What a day to be alive.\n",
            "\n",
            "This year's \"Survivor: Game Change\" season is shaping up to be one of the biggest.\n",
            "\n",
            "In the first round of the season, two of the top four contestants are coming back strong.\n",
            "\n",
            "Tami and Sam, who have competed in two of the top five seasons of Survivor, are now facing off again.\n",
            "\n",
            "Both are in the first round of the new season, where they'll be playing the game of life for the first time.\n",
            "\n",
            "\n",
            "= Perturbed generated text 1 =\n",
            "<|endoftext|>What a day to be alive.\n",
            "\n",
            "I'm a former high school basketball star and college basketball writer. I've been in politics for almost 40 years and am currently president of the University of Virginia's Board of Regents.\n",
            "\n",
            "I recently took the time to speak with the president of the college basketball business owners association to discuss the business side of basketball and why they are investing heavily in basketball.\n",
            "\n",
            "\"I think the business side of basketball is the most important business of business and sports business. It provides the business\n",
            "\n",
            "= Prefix of sentence =\n",
            "<|endoftext|>madam speaker. i yield myself such time as i may consume. madam speaker. i want to thank chairman lantos and\n",
            "\n",
            "= Unperturbed generated text =\n",
            "<|endoftext|>madam speaker. i yield myself such time as i may consume. madam speaker. i want to thank chairman lantos and i ask him to support our motion to authorize appropriations for the construction of the State of Nevada highway system and for the construction of a national highway system. i also ask that the speaker act commencing on the date of our next session. we thank Chairman Lantos and all members of the subcommittee for their consideration of this resolution.<|endoftext|>The world may be on a tear. The global temperature rise is expected to reach 2 degrees Celsius this century.\n",
            "\n",
            "According to research published in the journal Nature,\n",
            "\n",
            "= Perturbed generated text 1 =\n",
            "<|endoftext|>madam speaker. i yield myself such time as i may consume. madam speaker. i want to thank chairman lantos and i yield myself such time as i may consume. madam speaker. i have a great deal more to say. i yield myself such time as i may consume. madam speaker. i am a true friend to the people. i yield to the people of the republic. i have an interest in the stock market for a long time. i have bought into the bonds market and the bond business. the stock business and the securities business are my personal investments of my own making. i stock business is\n",
            "\n",
            "= Prefix of sentence =\n",
            "<|endoftext|>mr. president. i thank the chair. i thank my colleagues. let me be very clear. senators have a right to\n",
            "\n",
            "= Unperturbed generated text =\n",
            "<|endoftext|>mr. president. i thank the chair. i thank my colleagues. let me be very clear. senators have a right to ask for a vote on anything. the floor is full of people who are not doing their jobs. and i do not agree with the speaker. i believe that the president should ask the chairman to ask a vote. i do not believe we should be sitting on the floor debating the legislation. so i ask him to do his job. i ask the chair to vote. i urge him to move forward with this bill. i urge the chair to support the bill. i also ask the speaker to move\n",
            "\n",
            "= Perturbed generated text 1 =\n",
            "<|endoftext|>mr. president. i thank the chair. i thank my colleagues. let me be very clear. senators have a right to vote on everything they want. i want to be clear. i have the authority to do that. we will be working together on this. but i want to make sure that we have the resources necessary to support the defense of the United States. we will continue to work with our foreign counterparts on the defense industry to address global economic challenges. i believe we can do business through oil and gas. our oil industry has been a major source of transportation capital in the United oil industry. oil oil industry capital\n",
            "\n",
            "= Prefix of sentence =\n",
            "<|endoftext|>mr. speaker. i rise today to oppose this rule because i felt very strongly that this house should be given\n",
            "\n",
            "= Unperturbed generated text =\n",
            "<|endoftext|>mr. speaker. i rise today to oppose this rule because i felt very strongly that this house should be given the opportunity to vote on this important legislation. i will be voting on the bill because i will support the amendments and because i will be voting for the bill as it goes forward. the bill will give states the option of allowing localities to adopt a similar law. however. the rules on what is acceptable are unclear. i do believe this rule would allow states a chance to adopt a similar law. this is something i support.<|endoftext|>The world is changing. The average age is going to grow by\n",
            "\n",
            "= Perturbed generated text 1 =\n",
            "<|endoftext|>mr. speaker. i rise today to oppose this rule because i felt very strongly that this house should be given a more balanced approach. i am concerned that the rule is being used to discriminate against immigrants who are not from the united states and i am also concerned that we will not be getting the tax breaks that are needed to keep people working and growing their businesses. we have a very strong economy that is based around the oil industry. i think oil companies can be a very good business business and i think our oil industry has been a success story since we bought oil company oil company oil company oil oil company,\n",
            "\n",
            "= Prefix of sentence =\n",
            "<|endoftext|>madam president. i appreciate the efforts of the senator from idaho for small businessmen and women. for families who are\n",
            "\n",
            "= Unperturbed generated text =\n",
            "<|endoftext|>madam president. i appreciate the efforts of the senator from idaho for small businessmen and women. for families who are struggling to make ends meet. i also appreciate the efforts of the senate judiciary subcommittee chairman. i also appreciate the efforts of the president of united states. i am pleased that the president and senate are working together to ensure our nation has a fair, effective and transparent federal judiciary.<|endoftext|>A new study from the University of California at Berkeley's Center for the Study of Health and Behavior found that children who grow up on more restrictive diets consume more calories and fewer nutrients than do healthy adults. But the researchers also\n",
            "\n",
            "= Perturbed generated text 1 =\n",
            "<|endoftext|>madam president. i appreciate the efforts of the senator from idaho for small businessmen and women. for families who are struggling on the front lines. i want to thank the senator from virginia. i do say thursday the senator is an accomplished lawyer. but i have also heard of his son. i am a big supporter of the military family and the senator from virginia and i want to thank him for supporting clean energy. for oil and gas drilling leases. coal mining operations. natural gas leasing and oil drilling. oil and gas drilling projects in Texas oil refinery business\n",
            "\n",
            "gas refinery business oil gas gas gas\n",
            "\n",
            "= Prefix of sentence =\n",
            "<|endoftext|>i know you had referenced some slowing down of the process. this process must not slow down. we have decisions\n",
            "\n",
            "= Unperturbed generated text =\n",
            "<|endoftext|>i know you had referenced some slowing down of the process. this process must not slow down. we have decisions to make. it is our responsibility to ensure the safety of all of our workers. i will address you as soon as possible.<|endoftext|>by James H. O'Neill, BDN Staff • July 6, 2014 11:59 am\n",
            "\n",
            "Updated: July 6, 2014 7:14 am\n",
            "\n",
            "PORTLAND, Maine — A Portland man has been charged with first-degree murder in the death of a 15-year-old boy in a tragic crash that left his mother in the hospital.\n",
            "\n",
            "= Perturbed generated text 1 =\n",
            "<|endoftext|>i know you had referenced some slowing down of the process. this process must not slow down. we have decisions we make that we make with the public in the public interest. the process has a great deal more to do with the private sector than the public interest, but we do it on the private sector as a public company and we are not the private sector. we are private business. the public company is private business. the public company is private business. the private company is business business private private-'the'in and de- the and de'de of and \" in and the and \" and\n",
            "\n",
            "= Prefix of sentence =\n",
            "<|endoftext|>mr. speaker. on may 17. 1954. in the landmark case aimed at ending segregation in public schoolsbrown versus the board\n",
            "\n",
            "= Unperturbed generated text =\n",
            "<|endoftext|>mr. speaker. on may 17. 1954. in the landmark case aimed at ending segregation in public schoolsbrown versus the board. on may 16. 1954. the district held a hearing on whether to adopt a policy of desegregation and to recommend a resolution that would have prohibited racial segregated schools for blacks. the vote on the resolution was not unanimous. a resolution of no vote on the resolution. the resolution was then sent for consideration at a resolution conference held by all the schools. a resolution of no vote on the resolution was passed on May 29. 1957. the committee then held a hearing on the question of whether des\n",
            "\n",
            "= Perturbed generated text 1 =\n",
            "<|endoftext|>mr. speaker. on may 17. 1954. in the landmark case aimed at ending segregation in public schoolsbrown versus the board of education. a district court ruled that the district had no authority to enforce segregation. and the board of education did not have to pay for bus and streetcars. i was one of the few people to have my car insured. when it was stolen it is the only thing that could make my house safe. i had this house built in the middle of nowhere. i dont own stock in stock stock stock stock company stock stock stock stock stock stock stock stock stock--\n",
            "..:...:,\n",
            "\n",
            "= Prefix of sentence =\n",
            "<|endoftext|>mr. chairman. i rise in strong support of h.r. 985. and i do so for a number of reasons. we\n",
            "\n",
            "= Unperturbed generated text =\n",
            "<|endoftext|>mr. chairman. i rise in strong support of h.r. 985. and i do so for a number of reasons. we are pleased to note that h.r. 985 will address a number of significant issues. i would like to acknowledge a number of those senators who have expressed support for this bill. i will also address the fact that h.r. 985 was defeated by a strong majority of the full body of senators who supported it. i also recognize the support of a number of our other colleagues who have expressed support for h.r. 985. and i will thank them. as I said in\n",
            "\n",
            "= Perturbed generated text 1 =\n",
            "<|endoftext|>mr. chairman. i rise in strong support of h.r. 985. and i do so for a number of reasons. we are united in our call for a strong defense against terrorism and extremism. the world is suffering today from an unprecedented number of terrorist attacks. as we know, we face a global terrorism epidemic. the world is facing a growing number of attacks that are not just attacks on oil pipelines. oil is a natural resource commodity. the global oil price has been volatile for a number of years and is on a decline. this has led some oil companies to cut their oil production and oil refinery operations. oil refinery oil\n",
            "\n",
            "= Prefix of sentence =\n",
            "<|endoftext|>mr. chairman. i am not going to oppose the amendment to the amendment that i have offered. i do want\n",
            "\n",
            "= Unperturbed generated text =\n",
            "<|endoftext|>mr. chairman. i am not going to oppose the amendment to the amendment that i have offered. i do want to support the amendment that i will offer to congressmen. i am not going to oppose it because i do not support any other amendment that i have introduced. i will say that the amendment will help reduce the burden on children of a lot of people and provide the opportunity for states to adopt a similar policy. i do hope that the amendment will not be blocked because it would reduce the burden of a lot of people. i do want to be clear. i think the amendment is not about a burden\n",
            "\n",
            "= Perturbed generated text 1 =\n",
            "<|endoftext|>mr. chairman. i am not going to oppose the amendment to the amendment that i have offered. i do want to make sure we are doing something that is fair for everyone. the bill has a good chance to address the problems that have been identified as part of the tax law and is not subject to the alternative minimum tax. but i do believe that the tax is a very important business opportunity for businesses. i would like to thank our friends in the dairy business community. we have had great success and business is strong here in this city. the farm business association has business interests in business business operations business business business\n",
            "\n",
            "= Prefix of sentence =\n",
            "<|endoftext|>mr. president. i am very grateful we have moved forward on a very important bill for the countrythe travel promotion\n",
            "\n",
            "= Unperturbed generated text =\n",
            "<|endoftext|>mr. president. i am very grateful we have moved forward on a very important bill for the countrythe travel promotion act of 2009. i will be very happy to address the speaker of the house and urge her to support this bill. i ask my colleagues to support this bill. i also ask my colleagues to support the bipartisan bill in the Senate. we need to do everything in our power to pass this legislation. it is time to move forward with this important bill. i rise today to support the bipartisan bill. this is one of the first pieces of legislation we have to offer the american people which is a\n",
            "\n",
            "= Perturbed generated text 1 =\n",
            "<|endoftext|>mr. president. i am very grateful we have moved forward on a very important bill for the countrythe travel promotion act of 2006. i am pleased that our congressman and senator have supported it because it is critical to the safety and health of our nation and the economy. we have also worked to improve the quality of our education system. the administration has continued to invest in infrastructure. it has increased the federal credit rating and the federal reserve bank lending facility for small business. it has also expanded credit and loan guarantees to businesses in the auto industry. it has expanded credit credit and loan guarantees to businesses in the auto\n",
            "\n",
            "= Prefix of sentence =\n",
            "<|endoftext|>madam speaker. i rise in support of h.r. 3305. a bill introduced by the gentleman from oklahoma. which designates\n",
            "\n",
            "= Unperturbed generated text =\n",
            "<|endoftext|>madam speaker. i rise in support of h.r. 3305. a bill introduced by the gentleman from oklahoma. which designates a \"special interest tax credit.\" the credit would provide tax breaks for high-cost companies that are required to pay an \"investment tax\" to be included in sales taxes. the bill will give tax breaks to high-cost companies that pay a special interest rate. i applaud his leadership in this effort and hope that his leadership in this process helps us all to make good on our pledge of fiscal responsibility.<|endoftext|>The first of two new \"The Simpsons\" shows on FOX is on Friday night.\n",
            "\n",
            "= Perturbed generated text 1 =\n",
            "<|endoftext|>madam speaker. i rise in support of h.r. 3305. a bill introduced by the gentleman from oklahoma. which designates section 4 of title 31 of the american republic. and provides a mechanism by which congressmen may act as representatives to congress and to the people of america to ensure that the provisions of the american republic are fully and fully implemented. the american republic has been an institution for centuries and the american public has been a proud participant in its investment opportunities. but today it is time to raise the capital capital and invest in the electric transportation industry.\n",
            "\n",
            "Electricity is the second largest transportation\n",
            "\n",
            "= Prefix of sentence =\n",
            "<|endoftext|>i thank the gentleman for yielding. madam speaker. i rise in strong support of h.r. 4626. the health insurance industry\n",
            "\n",
            "= Unperturbed generated text =\n",
            "<|endoftext|>i thank the gentleman for yielding. madam speaker. i rise in strong support of h.r. 4626. the health insurance industry. this bill would provide insurance benefits for the uninsured and their dependents. i thank the gentleman for yielding. madam speaker. i rise in support of s. 757. the veterans housing act. the bill would provide a benefit to veterans with disabilities. the gentleman notes that i am very pleased that h.r. 4744 would provide additional support to a veterans benefit system. i also thank the gentleman for yielding. i rise in support of h.r. 2847. the homeland security\n",
            "\n",
            "= Perturbed generated text 1 =\n",
            "<|endoftext|>i thank the gentleman for yielding. madam speaker. i rise in strong support of h.r. 4626. the health insurance industry's right to provide a public option to individuals who need health insurance. the bill would provide subsidies to low-income families. it would provide subsidies to low-income workers who have lost their job or are looking for a new job. it would allow private companies and individuals with private business entities to provide subsidies to individuals for their private business activities. i also urge the speaker to provide tax credits to businesses to support the private sector in the private sector. i would also like the private sector to develop an\n",
            "\n",
            "= Prefix of sentence =\n",
            "<|endoftext|>mr. speaker. there are two reasons for the tax relief bill that we are considering on the floor this afternoon.\n",
            "\n",
            "= Unperturbed generated text =\n",
            "<|endoftext|>mr. speaker. there are two reasons for the tax relief bill that we are considering on the floor this afternoon. one is because it is a very bipartisan package to address the problem of high-cost, high-cost health care. and the other that is because it is not a partisan bill. it is not partisan. it is bipartisan. so we need to do both. we need to work together on one piece of legislation. and we do. that bill was introduced in the senate by Senator Rand Paul of Kentucky last week. he was a member of the senate health care committee for four terms. he was\n",
            "\n",
            "= Perturbed generated text 1 =\n",
            "<|endoftext|>mr. speaker. there are two reasons for the tax relief bill that we are considering on the floor this afternoon. we are looking to raise the capital gains tax on dividends and capital gains on capital gains. the second reason is that there were very significant changes to the capital gains tax rate. capital gains tax is a capital gain tax on dividends. we are going to increase capital gains tax on dividends by $100 million over the next five years. capital gains tax capital losses on capital capital capital stock capital capital capital stock capital capital capital capital stocky\n",
            ".<|endoftext|>.\n",
            "\n",
            "<|endoftext|>\n",
            "\n",
            ".:\n",
            "<|endoftext|><|endoftext|>\n",
            "\n",
            "= Prefix of sentence =\n",
            "<|endoftext|>mr. president. i congratulate everybody who was involved in the bill. this was not easy work. there were a lot\n",
            "\n",
            "= Unperturbed generated text =\n",
            "<|endoftext|>mr. president. i congratulate everybody who was involved in the bill. this was not easy work. there were a lot of amendments. i think i will make it harder tomorrow. but i am not satisfied. i will continue to push to make the bill stronger for everyone. including for seniors and disabled. i will make it more clear in my speech tomorrow. i want to address the issues that matter most to those who care about our seniors and disabled citizens. i will address the need to protect our seniors and disabled citizens in our democracy. i will make a strong commitment by our leadership to continue to address the concerns and\n",
            "\n",
            "= Perturbed generated text 1 =\n",
            "<|endoftext|>mr. president. i congratulate everybody who was involved in the bill. this was not easy work. there were a lot of changes that we needed to work on in the Senate. but the bill has a great chance to pass the House and the Senate will come to the floor with a bipartisan majority on the tax reform bill. this will be very important to our business and industry. and i hope that the bill does well and i think the businesses have confidence in the tax credit. it will help business and industry. our tax credit has been a major credit to businesses. it has helped pay for college debt credit. college\n",
            "\n",
            "= Prefix of sentence =\n",
            "<|endoftext|>madam speaker. i rise today in strong support of h.r. 2. the childrens health insurance program (chip) reauthorization act of\n",
            "\n",
            "= Unperturbed generated text =\n",
            "<|endoftext|>madam speaker. i rise today in strong support of h.r. 2. the childrens health insurance program (chip) reauthorization act of 2006. i call on our congressmen to vote on the bill as soon as possible. we are working to secure funding. our congressmen have already introduced a bill that would provide the insurance for the childrens health insurance program. i will ask my colleagues to support this amendment to ensure we do not pass a bill that would delay coverage for all childrens. our amendment would also allow the government to expand its health insurance coverage program for those individuals and businesses that offer health insurance. as a result,\n",
            "\n",
            "= Perturbed generated text 1 =\n",
            "<|endoftext|>madam speaker. i rise today in strong support of h.r. 2. the childrens health insurance program (chip) reauthorization act of 2008. i will support the bill as it relates to health insurance for the poor. it is critical that the law is balanced and does not provide subsidies, tax credits or other forms to private companies that are not in compliance with the health law. this act is a classic example of the bipartisan effort to improve the credit for businesses. i support the bipartisan credit reform credit rating agency credit credit rating agency credit rating credit credit credit credit credit the. \". $\n",
            "\n",
            "\n",
            "\n",
            ".:\n",
            " \"\n",
            "\n",
            "\n",
            "= Prefix of sentence =\n",
            "<|endoftext|>mr. speaker. if the gentleman will yield. let me just pick up on a point that i think all three\n",
            "\n",
            "= Unperturbed generated text =\n",
            "<|endoftext|>mr. speaker. if the gentleman will yield. let me just pick up on a point that i think all three of you have said. i will say it is very important that we are not only looking at the health care bill but also the health care bill. we need to understand what it is. and we will look at the whole of these two items. and we will talk about the individual mandate. and we will talk about the employer mandate. and we will talk a lot about the individual mandate. and then we will move on to the health care bill and what we may or may not have to consider\n",
            "\n",
            "= Perturbed generated text 1 =\n",
            "<|endoftext|>mr. speaker. if the gentleman will yield. let me just pick up on a point that i think all three of us are going to make. i think the first thing that the gentleman has to do is to address the debt ceiling. he will not do this because we will raise taxes on the wealthiest of us. he will not do this because we will increase taxes on the oil industry. the oil industry is going to take advantage of the stimulus package because of the oil industry. the oil industry and oil industry are going to pay back $100 billion in oil credit credit credit accounts. oil industry credit:S\n",
            "\n",
            "= Prefix of sentence =\n",
            "<|endoftext|>mr. speaker. every once in a while. a vote comes before us that is evidently more than important. and this\n",
            "\n",
            "= Unperturbed generated text =\n",
            "<|endoftext|>mr. speaker. every once in a while. a vote comes before us that is evidently more than important. and this is not one of them. i think it is important that we address the issue of the future of our democracy and how to address the issues of inequality. i believe that this has not been accomplished by a single bill in any of these two congresses or by the other three members of congress. it has occurred to me and all other members of our caucus. and it is a fact. that there was a bill in the senate that passed the committee and was not voted upon. and then a similar\n",
            "\n",
            "= Perturbed generated text 1 =\n",
            "<|endoftext|>mr. speaker. every once in a while. a vote comes before us that is evidently more than important. and this time is the first one. i want to make it very clear that the speaker of congress has no qualms with the death penalty. he says this because we will not be punished the way the states are. he goes on to say that the death penalty is a way to finance the prison construction sector. i think this is a good thing for the industry. it allows people to get their goods and services to the people. i do not know how much of that oil is capital capital stock. capital\n",
            "\n",
            "= Prefix of sentence =\n",
            "<|endoftext|>mr. president. it is perfectly clear our friends on the other side are more interested in pleasing special interest groups\n",
            "\n",
            "= Unperturbed generated text =\n",
            "<|endoftext|>mr. president. it is perfectly clear our friends on the other side are more interested in pleasing special interest groups. but what do they want us to do to win the war on terror. if they are willing to do anything but take away our freedoms? what about our security? what would the president do about it? if we do not act? what about the people? is that what they want?\n",
            "\n",
            "i am not sure if you know. but if they do. they are going to try to take our liberties. we do have a constitutional amendment and our constitution. it is not about a president\n",
            "\n",
            "= Perturbed generated text 1 =\n",
            "<|endoftext|>mr. president. it is perfectly clear our friends on the other side are more interested in pleasing special interest groups than protecting the country. i am willing to debate that. but as the president said. i believe we will be able to get to the point of making sure we do not overburden the economy and our own citizens. the tax code is the most efficient and transparent business system in America. the only companies to own more than $100 million of real estate are privately held real estate and leasing businesses. this company owned stock in the largest bank stock company of any corporation owned or operated by the stock\n",
            "\n",
            "= Prefix of sentence =\n",
            "<|endoftext|>mr. chairman. i yield myself the balance of my time. for years. republicans have fought on behalf of students and\n",
            "\n",
            "= Unperturbed generated text =\n",
            "<|endoftext|>mr. chairman. i yield myself the balance of my time. for years. republicans have fought on behalf of students and teachers. and i support them. i want to see our country move on from this. we are on the right path. i will vote for a bill that will help make sure the right to education is protected for all students. i will support a bill that will provide a $2.2 billion loan program to students and teachers who are working part time. a few more years in the making. this is one of the first things i will do when i am president. we must act together to\n",
            "\n",
            "= Perturbed generated text 1 =\n",
            "<|endoftext|>mr. chairman. i yield myself the balance of my time. for years. republicans have fought on behalf of students and teachers who are suffering under the unfair and unjust system. and i am committed to continue to fight for our students. and teachers and students. and taxpayers. we will not let this happen. the chairman and treasurer will not allow the sale of the property at auction and for sale through the company. the stock price of the company will not be sold. the company will pay dividends to shareholders and other stockholders. the stock price of the company will not be paid dividends. the stock stock stock stock company\n",
            "\n",
            "= Prefix of sentence =\n",
            "<|endoftext|>mr. speaker. let me say that obviously we are continuing to work on our quest to put into place for\n",
            "\n",
            "= Unperturbed generated text =\n",
            "<|endoftext|>mr. speaker. let me say that obviously we are continuing to work on our quest to put into place for the first time the \"free will principle\" to allow all individuals to participate. we have been in the process of working on a proposal that has been adopted by the Senate for a vote. and we will continue to work on it. we have a very good plan in place which is to make sure that all members of Congress have the opportunity to participate in any and all activities of their elected office. this is something that we have talked about in the senate for several months. we have not just talked\n",
            "\n",
            "= Perturbed generated text 1 =\n",
            "<|endoftext|>mr. speaker. let me say that obviously we are continuing to work on our quest to put into place for a more sustainable economy. we have a long track record of working with businesses. our economic development plan is a lot more comprehensive and it has been done by a lot of small business owners. there are a lot of small business owners working for the local food bank and other community businesses. there is some support for farmers businesses in the state of agriculture. we can do business with local farmers and farm businesses. we can grow agricultural crops from seed to food crops business farm business business business business business \",\n",
            "\n",
            "= Prefix of sentence =\n",
            "<|endoftext|>mr. speaker. i rise today to honor a true virginian and a great american. congressman norm sisisky. congressman sisisky has\n",
            "\n",
            "= Unperturbed generated text =\n",
            "<|endoftext|>mr. speaker. i rise today to honor a true virginian and a great american. congressman norm sisisky. congressman sisisky has been on the record calling for a comprehensive overhaul of our immigration system and for a national criminal justice reform program that will address a host of issues. i rise as a proud patriot. i believe that the federal government should not be responsible for immigration. i do not support a system that encourages illegal aliens from other countries to come into the country. i believe that it is a violation of the spirit of the United States of america that a person who is not an american citizen is not considered a citizen\n",
            "\n",
            "= Perturbed generated text 1 =\n",
            "<|endoftext|>mr. speaker. i rise today to honor a true virginian and a great american. congressman norm sisisky. congressman sisisky has spent more than a decade in the senate as the chairman of the committee on commerce and commerce and commerce appropriations committee. and he is chairman of the subcommittee on commerce. i will address the commerce committee tomorrow and tell my colleagues what we have here to accomplish. we have a responsibility to the treasury department to finance the transportation of commerce. and we have a responsibility to the commerce department to carry on commerce commerce commerce commerce commerce commerce the : the second my kind second s a very my kind kind second the s\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "run_pplm_example(\n",
        "    cond_text=\"The vote is an attempt by the party to protect abortion rights as states set increasingly restrictive laws.\",\n",
        "    num_samples=3,\n",
        "    bag_of_words='business',\n",
        "    discrim='generic',\n",
        "    discrim_meta=\"/content/gdrive/MyDrive/generic_classifier_head_meta.json\",\n",
        "    discrim_weights=\"/content/gdrive/MyDrive/generic_classifier_head_epoch_5.pt\",\n",
        "    class_label=0,\n",
        "    length=200,\n",
        "    stepsize=0.001,\n",
        "    sample=True,\n",
        "    num_iterations=3,\n",
        "    window_length=5,\n",
        "    gamma=1.5,\n",
        "    gm_scale=0.95,\n",
        "    kl_scale=0.01,\n",
        "    verbosity='regular'\n",
        ")"
      ],
      "metadata": {
        "id": "9lrBYbCw1r17"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}